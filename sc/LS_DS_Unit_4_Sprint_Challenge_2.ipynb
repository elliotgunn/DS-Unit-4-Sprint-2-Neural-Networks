{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5qzvRZYhxb_",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Chocolate Gummy Bears](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx2u8PiqhxcB",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Define the following terms:\n",
        "\n",
        "- **Neuron:** a neuron takes a set of inputs, weights that pass through an activation function. the activation function is what allows for non-linear behavior. the ouput is then sent as an input to neurons in the next layer, repeating the process (weighted sum of inputs + transformation with activation function; the weighted sum contains a bias term). \n",
        "- **Input Layer:** deals with the inputs only. it passes the data directly to the first hidden layer, after being multiplied by the weights between the first and second layer and passing through the activation function.  \n",
        "- **Hidden Layer:** any layer between the input and output layer. \n",
        "- **Output Layer:** transforms the hidden layer activations into whatever scale we wanted to have. \n",
        "- **Activation:** this is where non-linearity happens, or 'squashing'. they squish values into a smaller range. it is the non-linear transformation over the input signal, it decides whether a neuron is activate or not. it lights up when a high number (close to 1)\n",
        "- **Backpropagation:** the backprop algo computes the gradient of the cost function. (the cost function minimizes the average of the loss computed over the entire training data set)\n",
        "\n",
        "it tells us how quickly the cost changes when we change the weights and biases. (partial derviatives dC/dw and dC/db of cost function C). we can learn that a weight will learn slowly if the input neuron is low-activation. we can also use the equations to design activation functions with desired learning properties. for ex., if we choose a non-sigmoid activation function where theta is always positive/nve/never gets close to 0, this prevents the slow-down of learning that happens to sigmoid neurons when they saturate. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szh0rCIshxcC",
        "colab_type": "text"
      },
      "source": [
        "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
        "\n",
        "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
        "\n",
        "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
        "\n",
        "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
        "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "Qw3obgbDhxcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "candy = pd.read_csv('chocolate_gummy_bears.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputHidden": false,
        "inputHidden": false,
        "id": "ubR0R5LYhxcH",
        "colab_type": "code",
        "outputId": "741f87b6-aa39-4319-e33d-23cee0145898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "candy.head()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chocolate</th>\n",
              "      <th>gummy</th>\n",
              "      <th>ate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   chocolate  gummy  ate\n",
              "0          0      1    1\n",
              "1          1      0    1\n",
              "2          0      1    1\n",
              "3          0      0    0\n",
              "4          1      1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tedNrqBhxcM",
        "colab_type": "text"
      },
      "source": [
        "### Perceptron\n",
        "\n",
        "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
        "\n",
        "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co7SIF0oLXiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputHidden": false,
        "inputHidden": false,
        "id": "cEtSCZaihxcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start your candy perceptron here\n",
        "\n",
        "inputs = candy[['chocolate', 'gummy']].values\n",
        "correct_outputs = candy['ate'].values.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F8DdOkCIKo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30bff0a5-2ab8-4476-df0d-183d5d62a0e3"
      },
      "source": [
        "inputs.shape, correct_outputs.shape"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 2), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrR8ortvM-ta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "193dbaf9-174c-41d3-86dd-e290a63acb74"
      },
      "source": [
        "correct_outputs"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3QINXpv67-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# activation function + derivative for updating weights\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    \n",
        "    return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSIZPsE7wao6",
        "colab_type": "code",
        "outputId": "04cb58fa-b797-4dab-f29d-c426a03228eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# intialize random weights for the two inputs\n",
        "# we need a matrix of \n",
        "weights = 2 * np.random.random((2,1)) - 1\n",
        "weights"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13871912],\n",
              "       [-0.60270641]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQIZEmsxLDV",
        "colab_type": "code",
        "outputId": "631fff23-fcc9-4a07-f48e-89084f07d446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# now do this 10000 times for fine tuning\n",
        "for iteration in range(10000):\n",
        "    \n",
        "    # weighted sum of inputs/weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "    # calc error\n",
        "    error = correct_outputs - activated_output\n",
        "\n",
        "    adjustments = error * sigmoid_derivative(activated_output)\n",
        "\n",
        "    # update the weights:\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "\n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-255.02285518]\n",
            " [-414.99432639]]\n",
            "Output after training\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upd0HX4jxXsX",
        "colab_type": "text"
      },
      "source": [
        "Explain why you could not achieve a higher accuracy with a simple perceptron:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95z2twshxcP",
        "colab_type": "text"
      },
      "source": [
        "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
        "\n",
        "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
        "Your network must have one hidden layer.\n",
        "\n",
        "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuqMalmFLj-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = inputs\n",
        "y = correct_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkp8o8e2MnsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "799e511f-c03b-4e26-8750-5556b976d473"
      },
      "source": [
        "y"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXms1_3tMwQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c58f9ec1-d478-4c40-f6ef-a8836ad9bd75"
      },
      "source": [
        "y = correct_outputs.reshape(-1,1)\n",
        "y"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputHidden": false,
        "inputHidden": false,
        "id": "lEQS7w6ohxcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I want activations that correspond to negative weights to be lower\n",
        "# and activations that correspond to positive weights to be higher\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        # Set up Architecture of Neural Network\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 4\n",
        "        self.outputNodes = 1\n",
        "\n",
        "        # Initial Weights\n",
        "        # 2x3 Matrix Array for the First Layer\n",
        "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
        "       \n",
        "        # 3x1 Matrix Array for Hidden to Output\n",
        "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + np.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        Calculate the NN inference using feed forward.\n",
        "        aka \"predict\"\n",
        "        \"\"\"\n",
        "        \n",
        "        # Weighted sum of inputs => hidden layer\n",
        "        self.hidden_sum = np.dot(X, self.weights1)\n",
        "        \n",
        "        # Activations of weighted sum\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # Weight sum between hidden and output\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "        \n",
        "        # Final activation of output\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "        \n",
        "    def backward(self, X,y,o):\n",
        "        \"\"\"\n",
        "        Backward propagate through the network\n",
        "        \"\"\"\n",
        "        \n",
        "        # Error in Output\n",
        "        self.o_error = y - o\n",
        "        \n",
        "        # Apply Derivative of Sigmoid to error\n",
        "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
        "        # ^- aka hidden => output\n",
        "        # o_delta: overall gradient\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "        \n",
        "        # z2 error\n",
        "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "        # How much of that \"far off\" can explained by the input => hidden\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
        "        \n",
        "        # Adjustment to first set of weights (input => hidden)\n",
        "        self.weights1 += X.T.dot(self.z2_delta)\n",
        "        # Adjustment to second set of weights (hidden => output)\n",
        "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
        "        \n",
        "\n",
        "    def train(self, X, y):\n",
        "        o = self.feed_forward(X)\n",
        "        self.backward(X,y,o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDXFhf3HyCgP",
        "colab_type": "code",
        "outputId": "712c18f0-9726-435b-9a0a-2468e13c7506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train my 'net\n",
        "nn = NeuralNetwork()\n",
        "\n",
        "# Number of Epochs / Iterations\n",
        "for i in range(10000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('Input: \\n', X)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------EPOCH 1---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.80279814]\n",
            " [0.79251455]\n",
            " [0.80279814]\n",
            " ...\n",
            " [0.80279814]\n",
            " [0.80279814]\n",
            " [0.79251455]]\n",
            "Loss: \n",
            " 0.3341885619648168\n",
            "+---------EPOCH 2---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.43075117]\n",
            " [0.37377738]\n",
            " [0.43075117]\n",
            " ...\n",
            " [0.43075117]\n",
            " [0.43075117]\n",
            " [0.37377738]]\n",
            "Loss: \n",
            " 0.24985462985072399\n",
            "+---------EPOCH 3---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999228]\n",
            " [0.49997793]\n",
            " [0.49999228]\n",
            " ...\n",
            " [0.49999228]\n",
            " [0.49999228]\n",
            " [0.49997793]]\n",
            "Loss: \n",
            " 0.20115663958007654\n",
            "+---------EPOCH 4---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999235]\n",
            " [0.49997847]\n",
            " [0.49999235]\n",
            " ...\n",
            " [0.49999235]\n",
            " [0.49999235]\n",
            " [0.49997847]]\n",
            "Loss: \n",
            " 0.20115650559410383\n",
            "+---------EPOCH 5---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999241]\n",
            " [0.49997898]\n",
            " [0.49999241]\n",
            " ...\n",
            " [0.49999241]\n",
            " [0.49999241]\n",
            " [0.49997898]]\n",
            "Loss: \n",
            " 0.2011563775442182\n",
            "+---------EPOCH 1000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999919]\n",
            " [0.49999911]\n",
            " [0.49999919]\n",
            " ...\n",
            " [0.49999919]\n",
            " [0.49999919]\n",
            " [0.49999911]]\n",
            "Loss: \n",
            " 0.20115037805303979\n",
            "+---------EPOCH 2000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999957]\n",
            " [0.49999954]\n",
            " [0.49999957]\n",
            " ...\n",
            " [0.49999957]\n",
            " [0.49999957]\n",
            " [0.49999954]]\n",
            "Loss: \n",
            " 0.20115019866009248\n",
            "+---------EPOCH 3000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999971]\n",
            " [0.49999968]\n",
            " [0.49999971]\n",
            " ...\n",
            " [0.49999971]\n",
            " [0.49999971]\n",
            " [0.49999968]]\n",
            "Loss: \n",
            " 0.20115013590524555\n",
            "+---------EPOCH 4000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999978]\n",
            " [0.49999976]\n",
            " [0.49999978]\n",
            " ...\n",
            " [0.49999978]\n",
            " [0.49999978]\n",
            " [0.49999976]]\n",
            "Loss: \n",
            " 0.20115010389275634\n",
            "+---------EPOCH 5000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999982]\n",
            " [0.4999998 ]\n",
            " [0.49999982]\n",
            " ...\n",
            " [0.49999982]\n",
            " [0.49999982]\n",
            " [0.4999998 ]]\n",
            "Loss: \n",
            " 0.2011500844520019\n",
            "+---------EPOCH 6000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999985]\n",
            " [0.49999983]\n",
            " [0.49999985]\n",
            " ...\n",
            " [0.49999985]\n",
            " [0.49999985]\n",
            " [0.49999983]]\n",
            "Loss: \n",
            " 0.20115007137739344\n",
            "+---------EPOCH 7000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999987]\n",
            " [0.49999985]\n",
            " [0.49999987]\n",
            " ...\n",
            " [0.49999987]\n",
            " [0.49999987]\n",
            " [0.49999985]]\n",
            "Loss: \n",
            " 0.2011500619715915\n",
            "+---------EPOCH 8000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999988]\n",
            " [0.49999987]\n",
            " [0.49999988]\n",
            " ...\n",
            " [0.49999988]\n",
            " [0.49999988]\n",
            " [0.49999987]]\n",
            "Loss: \n",
            " 0.20115005487318782\n",
            "+---------EPOCH 9000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.4999999 ]\n",
            " [0.49999988]\n",
            " [0.4999999 ]\n",
            " ...\n",
            " [0.4999999 ]\n",
            " [0.4999999 ]\n",
            " [0.49999988]]\n",
            "Loss: \n",
            " 0.2011500493206868\n",
            "+---------EPOCH 10000---------+\n",
            "Input: \n",
            " [[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "Actual Output: \n",
            " [[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Predicted Output: \n",
            " [[0.49999991]\n",
            " [0.49999989]\n",
            " [0.49999991]\n",
            " ...\n",
            " [0.49999991]\n",
            " [0.49999991]\n",
            " [0.49999989]]\n",
            "Loss: \n",
            " 0.2011500448548078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DoHodqghxcT",
        "colab_type": "text"
      },
      "source": [
        "P.S. Don't try candy gummy bears. They're disgusting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDxS6EpQhxcT",
        "colab_type": "text"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "Tn0q98wXhxcU",
        "colab_type": "code",
        "outputId": "3ee86b33-1bc2-4065-f9c9-9b1e6071a616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>140</td>\n",
              "      <td>199</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>207</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "1     37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "138   57    1   0       110   201    0  ...      1      1.5      1   0     1       1\n",
              "204   62    0   0       160   164    0  ...      0      6.2      0   3     3       0\n",
              "24    40    1   3       140   199    0  ...      1      1.4      2   0     3       1\n",
              "91    57    1   0       132   207    0  ...      1      0.0      2   0     3       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGDf4JELyI8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(columns=['target'])\n",
        "y = df['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5hUR_6dyzDO",
        "colab_type": "code",
        "outputId": "0027236c-705a-43aa-a0ce-0fa31e04c02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((227, 13), (227,), (76, 13), (76,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJ1B9r5y3Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZxxtUG_zp9w",
        "colab_type": "text"
      },
      "source": [
        "### Baseline accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIGAQHwy6oc",
        "colab_type": "code",
        "outputId": "16f37c5d-8e23-4137-bd5a-a3db31799b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Important Hyperparameters\n",
        "inputs = X_train.shape[1]\n",
        "epochs = 50\n",
        "batch_size = 10\n",
        "\n",
        "# create model without tuning\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(15, activation='relu', input_shape=(inputs,)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "\n",
        "# add sigmoid for output layer,  because classification (see notes)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "          \n",
        "  \n",
        "# since dependent variable is binary, use the log loss function \n",
        "# if there are > 2 categroies in output, then use categorical_crossentropy\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_test,y_test), \n",
        "          epochs=epochs, \n",
        "          batch_size=batch_size,\n",
        "          verbose=True\n",
        "         )"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 227 samples, validate on 76 samples\n",
            "Epoch 1/50\n",
            "227/227 [==============================] - 2s 11ms/sample - loss: 0.7148 - acc: 0.4537 - val_loss: 0.7052 - val_acc: 0.4474\n",
            "Epoch 2/50\n",
            "227/227 [==============================] - 0s 311us/sample - loss: 0.6899 - acc: 0.5374 - val_loss: 0.6837 - val_acc: 0.5263\n",
            "Epoch 3/50\n",
            "227/227 [==============================] - 0s 337us/sample - loss: 0.6706 - acc: 0.6123 - val_loss: 0.6672 - val_acc: 0.6711\n",
            "Epoch 4/50\n",
            "227/227 [==============================] - 0s 373us/sample - loss: 0.6508 - acc: 0.7269 - val_loss: 0.6473 - val_acc: 0.7237\n",
            "Epoch 5/50\n",
            "227/227 [==============================] - 0s 340us/sample - loss: 0.6274 - acc: 0.7533 - val_loss: 0.6221 - val_acc: 0.7105\n",
            "Epoch 6/50\n",
            "227/227 [==============================] - 0s 345us/sample - loss: 0.5977 - acc: 0.7621 - val_loss: 0.5956 - val_acc: 0.7500\n",
            "Epoch 7/50\n",
            "227/227 [==============================] - 0s 333us/sample - loss: 0.5597 - acc: 0.7709 - val_loss: 0.5660 - val_acc: 0.7368\n",
            "Epoch 8/50\n",
            "227/227 [==============================] - 0s 371us/sample - loss: 0.5187 - acc: 0.7797 - val_loss: 0.5355 - val_acc: 0.7632\n",
            "Epoch 9/50\n",
            "227/227 [==============================] - 0s 370us/sample - loss: 0.4948 - acc: 0.7930 - val_loss: 0.5151 - val_acc: 0.7895\n",
            "Epoch 10/50\n",
            "227/227 [==============================] - 0s 369us/sample - loss: 0.4565 - acc: 0.8106 - val_loss: 0.4966 - val_acc: 0.8026\n",
            "Epoch 11/50\n",
            "227/227 [==============================] - 0s 368us/sample - loss: 0.4356 - acc: 0.8062 - val_loss: 0.4831 - val_acc: 0.8158\n",
            "Epoch 12/50\n",
            "227/227 [==============================] - 0s 356us/sample - loss: 0.4172 - acc: 0.8238 - val_loss: 0.4745 - val_acc: 0.8158\n",
            "Epoch 13/50\n",
            "227/227 [==============================] - 0s 344us/sample - loss: 0.4036 - acc: 0.8106 - val_loss: 0.4655 - val_acc: 0.8026\n",
            "Epoch 14/50\n",
            "227/227 [==============================] - 0s 328us/sample - loss: 0.3879 - acc: 0.8414 - val_loss: 0.4665 - val_acc: 0.8158\n",
            "Epoch 15/50\n",
            "227/227 [==============================] - 0s 354us/sample - loss: 0.3789 - acc: 0.8370 - val_loss: 0.4593 - val_acc: 0.8026\n",
            "Epoch 16/50\n",
            "227/227 [==============================] - 0s 339us/sample - loss: 0.3681 - acc: 0.8414 - val_loss: 0.4561 - val_acc: 0.8158\n",
            "Epoch 17/50\n",
            "227/227 [==============================] - 0s 354us/sample - loss: 0.3564 - acc: 0.8370 - val_loss: 0.4580 - val_acc: 0.8289\n",
            "Epoch 18/50\n",
            "227/227 [==============================] - 0s 374us/sample - loss: 0.3504 - acc: 0.8326 - val_loss: 0.4596 - val_acc: 0.8158\n",
            "Epoch 19/50\n",
            "227/227 [==============================] - 0s 353us/sample - loss: 0.3430 - acc: 0.8370 - val_loss: 0.4563 - val_acc: 0.8026\n",
            "Epoch 20/50\n",
            "227/227 [==============================] - 0s 334us/sample - loss: 0.3381 - acc: 0.8458 - val_loss: 0.4562 - val_acc: 0.7895\n",
            "Epoch 21/50\n",
            "227/227 [==============================] - 0s 315us/sample - loss: 0.3328 - acc: 0.8414 - val_loss: 0.4593 - val_acc: 0.8158\n",
            "Epoch 22/50\n",
            "227/227 [==============================] - 0s 308us/sample - loss: 0.3296 - acc: 0.8458 - val_loss: 0.4595 - val_acc: 0.7763\n",
            "Epoch 23/50\n",
            "227/227 [==============================] - 0s 365us/sample - loss: 0.3249 - acc: 0.8458 - val_loss: 0.4612 - val_acc: 0.8026\n",
            "Epoch 24/50\n",
            "227/227 [==============================] - 0s 330us/sample - loss: 0.3215 - acc: 0.8546 - val_loss: 0.4628 - val_acc: 0.8026\n",
            "Epoch 25/50\n",
            "227/227 [==============================] - 0s 348us/sample - loss: 0.3184 - acc: 0.8546 - val_loss: 0.4636 - val_acc: 0.8026\n",
            "Epoch 26/50\n",
            "227/227 [==============================] - 0s 373us/sample - loss: 0.3153 - acc: 0.8546 - val_loss: 0.4666 - val_acc: 0.8026\n",
            "Epoch 27/50\n",
            "227/227 [==============================] - 0s 301us/sample - loss: 0.3119 - acc: 0.8634 - val_loss: 0.4649 - val_acc: 0.8026\n",
            "Epoch 28/50\n",
            "227/227 [==============================] - 0s 306us/sample - loss: 0.3102 - acc: 0.8678 - val_loss: 0.4686 - val_acc: 0.8026\n",
            "Epoch 29/50\n",
            "227/227 [==============================] - 0s 340us/sample - loss: 0.3078 - acc: 0.8590 - val_loss: 0.4679 - val_acc: 0.8026\n",
            "Epoch 30/50\n",
            "227/227 [==============================] - 0s 299us/sample - loss: 0.3073 - acc: 0.8634 - val_loss: 0.4716 - val_acc: 0.8026\n",
            "Epoch 31/50\n",
            "227/227 [==============================] - 0s 306us/sample - loss: 0.3024 - acc: 0.8722 - val_loss: 0.4696 - val_acc: 0.8026\n",
            "Epoch 32/50\n",
            "227/227 [==============================] - 0s 344us/sample - loss: 0.3008 - acc: 0.8767 - val_loss: 0.4718 - val_acc: 0.8026\n",
            "Epoch 33/50\n",
            "227/227 [==============================] - 0s 358us/sample - loss: 0.3021 - acc: 0.8634 - val_loss: 0.4735 - val_acc: 0.8026\n",
            "Epoch 34/50\n",
            "227/227 [==============================] - 0s 332us/sample - loss: 0.2990 - acc: 0.8722 - val_loss: 0.4737 - val_acc: 0.8026\n",
            "Epoch 35/50\n",
            "227/227 [==============================] - 0s 314us/sample - loss: 0.2978 - acc: 0.8811 - val_loss: 0.4769 - val_acc: 0.8026\n",
            "Epoch 36/50\n",
            "227/227 [==============================] - 0s 334us/sample - loss: 0.2940 - acc: 0.8722 - val_loss: 0.4766 - val_acc: 0.8026\n",
            "Epoch 37/50\n",
            "227/227 [==============================] - 0s 339us/sample - loss: 0.2931 - acc: 0.8767 - val_loss: 0.4784 - val_acc: 0.8026\n",
            "Epoch 38/50\n",
            "227/227 [==============================] - 0s 330us/sample - loss: 0.2906 - acc: 0.8767 - val_loss: 0.4809 - val_acc: 0.8026\n",
            "Epoch 39/50\n",
            "227/227 [==============================] - 0s 311us/sample - loss: 0.2882 - acc: 0.8855 - val_loss: 0.4811 - val_acc: 0.8026\n",
            "Epoch 40/50\n",
            "227/227 [==============================] - 0s 300us/sample - loss: 0.2876 - acc: 0.8855 - val_loss: 0.4819 - val_acc: 0.8026\n",
            "Epoch 41/50\n",
            "227/227 [==============================] - 0s 343us/sample - loss: 0.2859 - acc: 0.8855 - val_loss: 0.4846 - val_acc: 0.8026\n",
            "Epoch 42/50\n",
            "227/227 [==============================] - 0s 341us/sample - loss: 0.2841 - acc: 0.8899 - val_loss: 0.4861 - val_acc: 0.8026\n",
            "Epoch 43/50\n",
            "227/227 [==============================] - 0s 306us/sample - loss: 0.2831 - acc: 0.8855 - val_loss: 0.4854 - val_acc: 0.8026\n",
            "Epoch 44/50\n",
            "227/227 [==============================] - 0s 358us/sample - loss: 0.2824 - acc: 0.8855 - val_loss: 0.4887 - val_acc: 0.8026\n",
            "Epoch 45/50\n",
            "227/227 [==============================] - 0s 341us/sample - loss: 0.2796 - acc: 0.8855 - val_loss: 0.4875 - val_acc: 0.8026\n",
            "Epoch 46/50\n",
            "227/227 [==============================] - 0s 300us/sample - loss: 0.2768 - acc: 0.8899 - val_loss: 0.4858 - val_acc: 0.8026\n",
            "Epoch 47/50\n",
            "227/227 [==============================] - 0s 309us/sample - loss: 0.2803 - acc: 0.8855 - val_loss: 0.4899 - val_acc: 0.8026\n",
            "Epoch 48/50\n",
            "227/227 [==============================] - 0s 336us/sample - loss: 0.2826 - acc: 0.8855 - val_loss: 0.4899 - val_acc: 0.8026\n",
            "Epoch 49/50\n",
            "227/227 [==============================] - 0s 363us/sample - loss: 0.2710 - acc: 0.8943 - val_loss: 0.4886 - val_acc: 0.7895\n",
            "Epoch 50/50\n",
            "227/227 [==============================] - 0s 357us/sample - loss: 0.2699 - acc: 0.9031 - val_loss: 0.4902 - val_acc: 0.7895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f412b791cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU3ezTdM1opb",
        "colab_type": "code",
        "outputId": "60341d48-fa36-435b-d285-b228eba952e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "results"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 0s 122us/sample - loss: 0.4902 - acc: 0.7895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4901960774471885, 0.7894737]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1uDT5qiz7sg",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6CRcZEezurl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. hyperparameter tuning\n",
        "\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def create_model(activation='relu', \n",
        "                 dropout_rate=0.1, \n",
        "                 init_mode='uniform',\n",
        "                 optimizer='adam'):\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(15, kernel_initializer=init_mode, activation=activation, input_shape=(inputs,)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, kernel_initializer=init_mode, activation=activation))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "    return model\n",
        "  \n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPck58uH0Csi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'batch_size': [1000],\n",
        "              'epochs': [20, 40],\n",
        "              'optimizer': ['adam', 'sgd'] ,\n",
        "#              'learning_rate': [0.001, 0.01] ,\n",
        "#              'momentum': [0, 0.2] ,\n",
        "              'activation': ['softmax', 'linear'],\n",
        "              'init_mode': ['uniform', 'normal'],\n",
        "              'dropout_rate': [0.0, 0.1, 0.2],\n",
        "#              'neurons': [1, 5, 10]\n",
        "              }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHTsrO0f0D8v",
        "colab_type": "code",
        "outputId": "b7f6587b-9829-4501-bd42-1886c5811683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-459cf1af1cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Report Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3257\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3259\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}